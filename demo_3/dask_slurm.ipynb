{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask - Using Maxwell via dask_jobqueue "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Jobs: 0\n",
      "Running Jobs: 0\n",
      "Pending Jobs: 0\n"
     ]
    }
   ],
   "source": [
    "def print_squeue(username='cpassow'):\n",
    "    import subprocess\n",
    "    process = subprocess.Popen(\"squeue -u \"+ username, stdout=subprocess.PIPE, shell=True)\n",
    "    (output, err) = process.communicate()\n",
    "    print('Total Jobs:', str(output).count(username))\n",
    "    print('Running Jobs:', str(output).count(' R '))\n",
    "    print('Pending Jobs:', str(output).count(' PD '))\n",
    "    \n",
    "print_squeue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_jobqueue import SLURMCluster\n",
    "from distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(queue = 'ps', cores =30 , processes = 1, memory = '200GB', walltime = '00:30:00',\n",
    "                      local_directory = './slurm_out', log_directory = './slurm_logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Jobs: 5\n",
      "Running Jobs: 5\n",
      "Pending Jobs: 0\n"
     ]
    }
   ],
   "source": [
    "print_squeue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://131.169.193.101:42698</li>\n",
       "  <li><b>Dashboard: </b><a href='http://131.169.193.101:8787/status' target='_blank'>http://131.169.193.101:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>5</li>\n",
       "  <li><b>Cores: </b>150</li>\n",
       "  <li><b>Memory: </b>1000.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://131.169.193.101:42698' processes=5 cores=150>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem: timing jumps in FL1 pp-laser\n",
    "\n",
    "During a recent beamtime we observed the pp-laser jumps in timing and decided to record this behavior via a FLASH GHz ADC.\n",
    "\n",
    "![title](jddd_adc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from beamtimedaqaccess import BeamtimeDaqAccess "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF files of 1 FEL block "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/asap3/flash/gpfs/bl1/2019/data/11006508/raw/hdf/online-1/'\n",
    "trace_addr = '/FL1/Experiment/BL1/ADQ412 GHz ADC/CH01/TD'\n",
    "\n",
    "daq = BeamtimeDaqAccess.create(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rising_edges(run_number):\n",
    "    trace = np.asarray(daq.allValuesOfRun(trace_addr, run_number))\n",
    "    rising_edges = [np.argmax(trace[0][index] > 100) for index in range(len(trace[0])) if np.argmax(trace[0][index]) > 0 ]\n",
    "    unique, counts = np.unique(rising_edges, return_counts=True)    \n",
    "    edges = dict(zip(unique, counts))\n",
    "    return edges\n",
    "\n",
    "def counting(edges):\n",
    "    late = np.sum((np.asarray([v for k,v in edges.items() if k >= 2100])))\n",
    "    early = np.sum((np.asarray([v for k,v in edges.items() if k > 10 and k < 2100])))\n",
    "    if early > 0 and late > 0:\n",
    "        ratio = early / (early + late)\n",
    "        ratio = float(\"{0:.2f}\".format(ratio))\n",
    "    else:\n",
    "        ratio = np.nan\n",
    "    return [late,early, ratio]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check # of DAQ runs in FEL block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total # of DAQ runs: 85\n"
     ]
    }
   ],
   "source": [
    "runs = [int(f[93:98]) for f in glob.glob(root_dir + '/fl1user1/*_file1_*')]\n",
    "runs.sort()\n",
    "print('total # of DAQ runs:',len(runs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = runs[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask \n",
    "\n",
    "number_of_edges_per_run = []\n",
    "for run in runs:\n",
    "    number_of_edges = dask.delayed(get_rising_edges)(run)\n",
    "    number_of_edges_per_run.append(number_of_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 664 ms, sys: 39.5 ms, total: 703 ms\n",
      "Wall time: 12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dict_early_late = dask.compute(*number_of_edges_per_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistic for eLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 30067 Time Bins {2093: 119, 2094: 3766, 2095: 157, 2112: 192, 2113: 162}\n",
      "Run: 30068 Time Bins {2093: 169, 2094: 4651, 2095: 207, 2112: 215, 2113: 214}\n",
      "Run: 30069 Time Bins {2093: 86, 2094: 2840, 2095: 154, 2112: 155, 2113: 103}\n",
      "Run: 30070 Time Bins {2093: 55, 2094: 2716, 2095: 177, 2112: 115, 2113: 123}\n",
      "Run: 30071 Time Bins {2093: 65, 2094: 3665, 2095: 267}\n",
      "Run: 30073 Time Bins {2093: 40, 2094: 1653, 2095: 135}\n",
      "Run: 30074 no Laser\n",
      "Run: 30075 Time Bins {2093: 48, 2094: 2935, 2095: 243}\n",
      "Run: 30076 Time Bins {2093: 41, 2094: 2315, 2095: 170}\n",
      "Run: 30077 Time Bins {2093: 18, 2094: 1037, 2095: 71}\n",
      "\n",
      "RUN | late | early | ratio\n",
      "30067 [354, 4042, 0.92]\n",
      "30068 [429, 5027, 0.92]\n",
      "30069 [258, 3080, 0.92]\n",
      "30070 [238, 2948, 0.93]\n",
      "30071 [0.0, 3997, nan]\n",
      "30073 [0.0, 1828, nan]\n",
      "30074 [0.0, 0.0, nan]\n",
      "30075 [0.0, 3226, nan]\n",
      "30076 [0.0, 2526, nan]\n",
      "30077 [0.0, 1126, nan]\n"
     ]
    }
   ],
   "source": [
    "results = [counting(dict_early_late[index]) for index in range(len(dict_early_late))]\n",
    "\n",
    "for i in range(len(runs)):\n",
    "    if len(dict_early_late[i]) > 1:\n",
    "        print('Run:',runs[i],'Time Bins',dict_early_late[i])\n",
    "    else:\n",
    "        print('Run:',runs[i],'no Laser')\n",
    "        \n",
    "print('\\nRUN | late | early | ratio')\n",
    "for i in range(len(results)):\n",
    "    print(runs[i], results[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster termination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cluster.close()\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Jobs: 0\n",
      "Running Jobs: 0\n",
      "Pending Jobs: 0\n"
     ]
    }
   ],
   "source": [
    "print_squeue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:flash]",
   "language": "python",
   "name": "conda-env-flash-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
